{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing required packages\n",
    "Install nltk, pandas, gensim packages by performing the following commands in the terminal or command prompt:\n",
    "`pip install --upgrade nltk pandas gensim`\n",
    "or\n",
    "`conda install nltk pandas gensim`\n",
    "based on the python environment of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qa_id</th>\n      <th>question_title</th>\n      <th>question_body</th>\n      <th>question_user_name</th>\n      <th>question_user_page</th>\n      <th>answer</th>\n      <th>answer_user_name</th>\n      <th>answer_user_page</th>\n      <th>url</th>\n      <th>category</th>\n      <th>...</th>\n      <th>question_well_written</th>\n      <th>answer_helpful</th>\n      <th>answer_level_of_information</th>\n      <th>answer_plausible</th>\n      <th>answer_relevance</th>\n      <th>answer_satisfaction</th>\n      <th>answer_type_instructions</th>\n      <th>answer_type_procedure</th>\n      <th>answer_type_reason_explanation</th>\n      <th>answer_well_written</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>What am I losing when using extension tubes in...</td>\n      <td>After playing around with macro photography on...</td>\n      <td>ysap</td>\n      <td>https://photo.stackexchange.com/users/1024</td>\n      <td>I just got extension tubes, so here's the skin...</td>\n      <td>rfusca</td>\n      <td>https://photo.stackexchange.com/users/1917</td>\n      <td>http://photo.stackexchange.com/questions/9169/...</td>\n      <td>LIFE_ARTS</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.800000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1</td>\n      <td>What is the distinction between a city and a s...</td>\n      <td>I am trying to understand what kinds of places...</td>\n      <td>russellpierce</td>\n      <td>https://rpg.stackexchange.com/users/8774</td>\n      <td>It might be helpful to look into the definitio...</td>\n      <td>Erik Schmidt</td>\n      <td>https://rpg.stackexchange.com/users/1871</td>\n      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n      <td>CULTURE</td>\n      <td>...</td>\n      <td>0.888889</td>\n      <td>0.888889</td>\n      <td>0.555556</td>\n      <td>0.888889</td>\n      <td>0.888889</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.666667</td>\n      <td>0.888889</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2</td>\n      <td>Maximum protusion length for through-hole comp...</td>\n      <td>I'm working on a PCB that has through-hole com...</td>\n      <td>Joe Baker</td>\n      <td>https://electronics.stackexchange.com/users/10157</td>\n      <td>Do you even need grooves?  We make several pro...</td>\n      <td>Dwayne Reid</td>\n      <td>https://electronics.stackexchange.com/users/64754</td>\n      <td>http://electronics.stackexchange.com/questions...</td>\n      <td>SCIENCE</td>\n      <td>...</td>\n      <td>0.777778</td>\n      <td>0.777778</td>\n      <td>0.555556</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>1.000000</td>\n      <td>0.888889</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3</td>\n      <td>Can an affidavit be used in Beit Din?</td>\n      <td>An affidavit, from what i understand, is basic...</td>\n      <td>Scimonster</td>\n      <td>https://judaism.stackexchange.com/users/5151</td>\n      <td>Sending an \"affidavit\" it is a dispute between...</td>\n      <td>Y     e     z</td>\n      <td>https://judaism.stackexchange.com/users/4794</td>\n      <td>http://judaism.stackexchange.com/questions/551...</td>\n      <td>CULTURE</td>\n      <td>...</td>\n      <td>0.888889</td>\n      <td>0.833333</td>\n      <td>0.333333</td>\n      <td>0.833333</td>\n      <td>1.000000</td>\n      <td>0.800000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5</td>\n      <td>How do you make a binary image in Photoshop?</td>\n      <td>I am trying to make a binary image. I want mor...</td>\n      <td>leigero</td>\n      <td>https://graphicdesign.stackexchange.com/users/...</td>\n      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n      <td>q2ra</td>\n      <td>https://graphicdesign.stackexchange.com/users/...</td>\n      <td>http://graphicdesign.stackexchange.com/questio...</td>\n      <td>LIFE_ARTS</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.800000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 41 columns</p>\n</div>",
      "text/plain": "   qa_id                                     question_title  \\\n0      0  What am I losing when using extension tubes in...   \n1      1  What is the distinction between a city and a s...   \n2      2  Maximum protusion length for through-hole comp...   \n3      3              Can an affidavit be used in Beit Din?   \n4      5       How do you make a binary image in Photoshop?   \n\n                                       question_body question_user_name  \\\n0  After playing around with macro photography on...               ysap   \n1  I am trying to understand what kinds of places...      russellpierce   \n2  I'm working on a PCB that has through-hole com...          Joe Baker   \n3  An affidavit, from what i understand, is basic...         Scimonster   \n4  I am trying to make a binary image. I want mor...            leigero   \n\n                                  question_user_page  \\\n0         https://photo.stackexchange.com/users/1024   \n1           https://rpg.stackexchange.com/users/8774   \n2  https://electronics.stackexchange.com/users/10157   \n3       https://judaism.stackexchange.com/users/5151   \n4  https://graphicdesign.stackexchange.com/users/...   \n\n                                              answer answer_user_name  \\\n0  I just got extension tubes, so here's the skin...           rfusca   \n1  It might be helpful to look into the definitio...     Erik Schmidt   \n2  Do you even need grooves?  We make several pro...      Dwayne Reid   \n3  Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n4  Check out Image Trace in Adobe Illustrator. \\n...             q2ra   \n\n                                    answer_user_page  \\\n0         https://photo.stackexchange.com/users/1917   \n1           https://rpg.stackexchange.com/users/1871   \n2  https://electronics.stackexchange.com/users/64754   \n3       https://judaism.stackexchange.com/users/4794   \n4  https://graphicdesign.stackexchange.com/users/...   \n\n                                                 url   category  ...  \\\n0  http://photo.stackexchange.com/questions/9169/...  LIFE_ARTS  ...   \n1  http://rpg.stackexchange.com/questions/47820/w...    CULTURE  ...   \n2  http://electronics.stackexchange.com/questions...    SCIENCE  ...   \n3  http://judaism.stackexchange.com/questions/551...    CULTURE  ...   \n4  http://graphicdesign.stackexchange.com/questio...  LIFE_ARTS  ...   \n\n  question_well_written  answer_helpful  answer_level_of_information  \\\n0              1.000000        1.000000                     0.666667   \n1              0.888889        0.888889                     0.555556   \n2              0.777778        0.777778                     0.555556   \n3              0.888889        0.833333                     0.333333   \n4              1.000000        1.000000                     0.666667   \n\n   answer_plausible  answer_relevance  answer_satisfaction  \\\n0          1.000000          1.000000             0.800000   \n1          0.888889          0.888889             0.666667   \n2          1.000000          1.000000             0.666667   \n3          0.833333          1.000000             0.800000   \n4          1.000000          1.000000             0.800000   \n\n   answer_type_instructions  answer_type_procedure  \\\n0                       1.0               0.000000   \n1                       0.0               0.000000   \n2                       0.0               0.333333   \n3                       0.0               0.000000   \n4                       1.0               0.000000   \n\n   answer_type_reason_explanation  answer_well_written  \n0                        0.000000             1.000000  \n1                        0.666667             0.888889  \n2                        1.000000             0.888889  \n3                        1.000000             1.000000  \n4                        1.000000             1.000000  \n\n[5 rows x 41 columns]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Total records in the data frame: 6079\n"
    }
   ],
   "source": [
    "print(\"Total records in the data frame: {}\" .format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "30"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_columns = df.columns.values[1:].tolist()[0:10]\n",
    "\n",
    "y_columns = df.columns.values[1:].tolist()[10:40]\n",
    "len(y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnColumn(x, start, stop) :\n",
    "    return list(x[start:stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(6079, 10)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = list()\n",
    "for row in df.values :\n",
    "    X.append(returnColumn(row, 0, 10))\n",
    "X = pd.DataFrame(X, columns=x_columns)\n",
    "X.head()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(6079, 30)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = list()\n",
    "for row in df.values:\n",
    "    Y.append(returnColumn(row, 11, 41))\n",
    "Y = pd.DataFrame(Y, columns=y_columns)\n",
    "Y.head()\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(4863, 10) (4863, 30)\n(1216, 10) (1216, 30)\n"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_title = df[\"question_title\"]\n",
    "question_body = df[\"question_body\"]\n",
    "answer = df[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['how', 'often', 'do', 'i', 'need', 'to', 'change', 'my', 'oil', 'in', 'a', 'vw', 'tdi', '?']\n"
    }
   ],
   "source": [
    "# Create an object for word tokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "print(tokenizer.tokenize(question_title[20].lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenized lists of question title, question body and answer\n",
    "tokenized_q_title = list()\n",
    "for line in question_title:\n",
    "    tokenized_q_title.append(tokenizer.tokenize(line.lower()))\n",
    "\n",
    "tokenized_q_body = list()\n",
    "for line in question_body:\n",
    "    tokenized_q_body.append(tokenizer.tokenize(line.lower()))\n",
    "\n",
    "tokenized_answer = list()\n",
    "for line in answer:\n",
    "    tokenized_answer.append(tokenizer.tokenize(line.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['i', 'think', 'you', 'need', 'to', 'read', 'about', 'projects', 'and', 'solutions', ':', 'http', '://', 'msdn', '.', 'microsoft', '.', 'com', '/', 'en', '-', 'us', '/', 'library', '/', 'ee817674', '.', 'aspx', 'and', 'after', 'that', 'it', 'all', 'becomes', 'more', 'clear', ':', 'have', 'one', 'solution', ',', 'inside', 'of', 'that', 'solution', 'create', 'a', 'project', 'for', 'your', 'application', 'and', 'a', 'project', 'for', 'your', 'unit', '-', 'tests', '.', 'in', 'test', '-', 'project', 'add', 'reference', 'to', 'the', 'testing', 'framework', 'of', 'your', 'choice', 'and', 'a', 'reference', 'to', 'your', 'application', '-', 'project', '.', 'this', 'way', 'your', 'application', 'does', 'not', 'know', 'about', 'your', 'tests', 'and', 'compiled', 'into', 'one', 'assembly', '.', 'at', 'the', 'same', 'time', 'your', 'tests', 'depend', 'on', 'your', 'application', ',', 'but', 'compiled', 'into', 'another', 'assembly', ',', 'which', 'can', 'be', 'used', 'by', 'your', 'test', '-', 'runner', 'gui', '/', 'ci', 'or', 'whatever', 'else', 'you', 'use', '.', 'and', 'to', 'answer', 'your', 'next', 'question', ',', 'for', 'test', '-', 'project', 'you', 'need', 'to', 'choose', 'project', 'type', 'of', '\"', 'library', '\"', '(', 'console', 'application', 'will', 'work', 'as', 'well', 'if', 'you', 'like', ')']\n"
    }
   ],
   "source": [
    "# Checking if the answer block is well tokenized\n",
    "print(tokenized_answer[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "i think you need to read about projects and solutions : http :// msdn . microsoft . com / en - us / library / ee817674 . aspx and after that it all becomes more clear : have one solution , inside of that solution create a project for your application and a project for your unit - tests . in test - project add reference to the testing framework of your choice and a reference to your application - project . this way your application does not know about your tests and compiled into one assembly . at the same time your tests depend on your application , but compiled into another assembly , which can be used by your test - runner gui / ci or whatever else you use . and to answer your next question , for test - project you need to choose project type of \" library \" ( console application will work as well if you like )\n"
    }
   ],
   "source": [
    "# Joining the tokenized answer\n",
    "print(' '.join(tokenized_answer[34]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(tokenized_q_body, size=40, min_count=5, window=6).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.23921941,  0.13013904, -0.19032788,  0.01522156, -0.47804752,\n        0.16582343, -0.19456829, -0.21829945, -0.2174466 ,  0.30487815,\n        0.22614269, -0.41361937, -0.0401662 ,  0.5422716 ,  0.1694647 ,\n        0.5381826 , -0.2069952 , -0.33938038,  0.04561912,  0.16476537,\n       -0.16241425,  0.09392896,  0.00770915,  0.3346215 ,  0.25071475,\n       -0.10255306, -0.03189423,  0.20490131, -0.5458475 ,  0.05711024,\n        0.36852008, -0.1193844 ,  0.001635  ,  0.47262362, -0.19054806,\n        0.02217318,  0.17378293,  0.06826955,  0.11293535, -0.19327132],\n      dtype=float32)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_vector(\"framework\")       # Some random word in the question_title column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('app', 0.8447062969207764),\n ('wordpress', 0.7844392657279968),\n ('website', 0.7842112183570862),\n ('setup', 0.7810954451560974),\n ('configuration', 0.7742068767547607),\n ('application', 0.7726293802261353),\n ('successfully', 0.7659796476364136),\n ('web', 0.7500545978546143),\n ('blog', 0.7442182302474976),\n ('site', 0.7438467144966125)]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = list()      # All corpus available in the dataset\n",
    "\n",
    "for line in tokenized_q_title:\n",
    "    all_sentences.append(line)\n",
    "\n",
    "for line in tokenized_q_body:\n",
    "    all_sentences.append(line)\n",
    "\n",
    "for line in tokenized_answer:\n",
    "    all_sentences.append(line)\n",
    "\n",
    "# print(all_sentences[100])\n",
    "\n",
    "large_model = Word2Vec(all_sentences, size=40, min_count=5, window=6).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.22614406,  0.18407774,  0.6273944 ,  0.94544655,  0.22035408,\n        0.18214102, -0.3569308 , -0.0504012 , -0.2627686 , -0.21002813,\n       -0.16079727,  0.26206252,  0.1478542 ,  0.68146396, -0.01279862,\n        0.36174372,  0.579124  , -0.4415604 ,  0.03232605,  0.17362575,\n       -0.14464389,  0.09915953,  0.51756305,  0.49285233,  0.59476954,\n        0.12805662, -0.5631401 , -0.35877237, -0.37548807,  0.40246978,\n        0.63577414, -0.19661742, -0.18706313,  0.35731423, -0.5009254 ,\n       -0.15280549,  0.07309064,  0.03921694, -0.05773719, -0.3923961 ],\n      dtype=float32)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_model.get_vector(\"framework\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('app', 0.9100373387336731),\n ('application', 0.826718270778656),\n ('website', 0.8237828016281128),\n ('setup', 0.8108820915222168),\n ('client', 0.7995128035545349),\n ('browser', 0.7990148067474365),\n ('internet', 0.7952461242675781),\n ('plugin', 0.7892935276031494),\n ('wordpress', 0.7768241763114929),\n ('web', 0.7724286913871765)]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_model.most_similar(\"project\")\n",
    "# large_model.most_similar(positive=[\"project\"], negative=[\"wordpress\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['.', 'up', 'very', 'did', 'option', 'save', 'property', 'problems', 'packages', 'vector']\n"
    }
   ],
   "source": [
    "# Select the 1000 most frequently used words and sort them in descending order based on their frequency of usage\n",
    "words = sorted(model.vocab.keys(), key=lambda word: model.vocab[word].count, reverse=True)[:1000]\n",
    "\n",
    "print(words[::100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python37164bitbasecondaac0852bd93594678aebe973eda693d6e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}