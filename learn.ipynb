{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing required packages\n",
    "Install nltk, pandas, gensim packages by performing the following commands in the terminal or command prompt:\n",
    "`pip install --upgrade nltk pandas gensim`\n",
    "or\n",
    "`conda install nltk pandas gensim`\n",
    "based on the python environment of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qa_id</th>\n      <th>question_title</th>\n      <th>question_body</th>\n      <th>question_user_name</th>\n      <th>question_user_page</th>\n      <th>answer</th>\n      <th>answer_user_name</th>\n      <th>answer_user_page</th>\n      <th>url</th>\n      <th>category</th>\n      <th>...</th>\n      <th>question_well_written</th>\n      <th>answer_helpful</th>\n      <th>answer_level_of_information</th>\n      <th>answer_plausible</th>\n      <th>answer_relevance</th>\n      <th>answer_satisfaction</th>\n      <th>answer_type_instructions</th>\n      <th>answer_type_procedure</th>\n      <th>answer_type_reason_explanation</th>\n      <th>answer_well_written</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>0</td>\n      <td>What am I losing when using extension tubes in...</td>\n      <td>After playing around with macro photography on...</td>\n      <td>ysap</td>\n      <td>https://photo.stackexchange.com/users/1024</td>\n      <td>I just got extension tubes, so here's the skin...</td>\n      <td>rfusca</td>\n      <td>https://photo.stackexchange.com/users/1917</td>\n      <td>http://photo.stackexchange.com/questions/9169/...</td>\n      <td>LIFE_ARTS</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.800000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>1</td>\n      <td>What is the distinction between a city and a s...</td>\n      <td>I am trying to understand what kinds of places...</td>\n      <td>russellpierce</td>\n      <td>https://rpg.stackexchange.com/users/8774</td>\n      <td>It might be helpful to look into the definitio...</td>\n      <td>Erik Schmidt</td>\n      <td>https://rpg.stackexchange.com/users/1871</td>\n      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n      <td>CULTURE</td>\n      <td>...</td>\n      <td>0.888889</td>\n      <td>0.888889</td>\n      <td>0.555556</td>\n      <td>0.888889</td>\n      <td>0.888889</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.666667</td>\n      <td>0.888889</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2</td>\n      <td>Maximum protusion length for through-hole comp...</td>\n      <td>I'm working on a PCB that has through-hole com...</td>\n      <td>Joe Baker</td>\n      <td>https://electronics.stackexchange.com/users/10157</td>\n      <td>Do you even need grooves?  We make several pro...</td>\n      <td>Dwayne Reid</td>\n      <td>https://electronics.stackexchange.com/users/64754</td>\n      <td>http://electronics.stackexchange.com/questions...</td>\n      <td>SCIENCE</td>\n      <td>...</td>\n      <td>0.777778</td>\n      <td>0.777778</td>\n      <td>0.555556</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>1.000000</td>\n      <td>0.888889</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>3</td>\n      <td>Can an affidavit be used in Beit Din?</td>\n      <td>An affidavit, from what i understand, is basic...</td>\n      <td>Scimonster</td>\n      <td>https://judaism.stackexchange.com/users/5151</td>\n      <td>Sending an \"affidavit\" it is a dispute between...</td>\n      <td>Y     e     z</td>\n      <td>https://judaism.stackexchange.com/users/4794</td>\n      <td>http://judaism.stackexchange.com/questions/551...</td>\n      <td>CULTURE</td>\n      <td>...</td>\n      <td>0.888889</td>\n      <td>0.833333</td>\n      <td>0.333333</td>\n      <td>0.833333</td>\n      <td>1.000000</td>\n      <td>0.800000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>5</td>\n      <td>How do you make a binary image in Photoshop?</td>\n      <td>I am trying to make a binary image. I want mor...</td>\n      <td>leigero</td>\n      <td>https://graphicdesign.stackexchange.com/users/...</td>\n      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n      <td>q2ra</td>\n      <td>https://graphicdesign.stackexchange.com/users/...</td>\n      <td>http://graphicdesign.stackexchange.com/questio...</td>\n      <td>LIFE_ARTS</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.800000</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 41 columns</p>\n</div>",
      "text/plain": "   qa_id                                     question_title  \\\n0      0  What am I losing when using extension tubes in...   \n1      1  What is the distinction between a city and a s...   \n2      2  Maximum protusion length for through-hole comp...   \n3      3              Can an affidavit be used in Beit Din?   \n4      5       How do you make a binary image in Photoshop?   \n\n                                       question_body question_user_name  \\\n0  After playing around with macro photography on...               ysap   \n1  I am trying to understand what kinds of places...      russellpierce   \n2  I'm working on a PCB that has through-hole com...          Joe Baker   \n3  An affidavit, from what i understand, is basic...         Scimonster   \n4  I am trying to make a binary image. I want mor...            leigero   \n\n                                  question_user_page  \\\n0         https://photo.stackexchange.com/users/1024   \n1           https://rpg.stackexchange.com/users/8774   \n2  https://electronics.stackexchange.com/users/10157   \n3       https://judaism.stackexchange.com/users/5151   \n4  https://graphicdesign.stackexchange.com/users/...   \n\n                                              answer answer_user_name  \\\n0  I just got extension tubes, so here's the skin...           rfusca   \n1  It might be helpful to look into the definitio...     Erik Schmidt   \n2  Do you even need grooves?  We make several pro...      Dwayne Reid   \n3  Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n4  Check out Image Trace in Adobe Illustrator. \\n...             q2ra   \n\n                                    answer_user_page  \\\n0         https://photo.stackexchange.com/users/1917   \n1           https://rpg.stackexchange.com/users/1871   \n2  https://electronics.stackexchange.com/users/64754   \n3       https://judaism.stackexchange.com/users/4794   \n4  https://graphicdesign.stackexchange.com/users/...   \n\n                                                 url   category  ...  \\\n0  http://photo.stackexchange.com/questions/9169/...  LIFE_ARTS  ...   \n1  http://rpg.stackexchange.com/questions/47820/w...    CULTURE  ...   \n2  http://electronics.stackexchange.com/questions...    SCIENCE  ...   \n3  http://judaism.stackexchange.com/questions/551...    CULTURE  ...   \n4  http://graphicdesign.stackexchange.com/questio...  LIFE_ARTS  ...   \n\n  question_well_written  answer_helpful  answer_level_of_information  \\\n0              1.000000        1.000000                     0.666667   \n1              0.888889        0.888889                     0.555556   \n2              0.777778        0.777778                     0.555556   \n3              0.888889        0.833333                     0.333333   \n4              1.000000        1.000000                     0.666667   \n\n   answer_plausible  answer_relevance  answer_satisfaction  \\\n0          1.000000          1.000000             0.800000   \n1          0.888889          0.888889             0.666667   \n2          1.000000          1.000000             0.666667   \n3          0.833333          1.000000             0.800000   \n4          1.000000          1.000000             0.800000   \n\n   answer_type_instructions  answer_type_procedure  \\\n0                       1.0               0.000000   \n1                       0.0               0.000000   \n2                       0.0               0.333333   \n3                       0.0               0.000000   \n4                       1.0               0.000000   \n\n   answer_type_reason_explanation  answer_well_written  \n0                        0.000000             1.000000  \n1                        0.666667             0.888889  \n2                        1.000000             0.888889  \n3                        1.000000             1.000000  \n4                        1.000000             1.000000  \n\n[5 rows x 41 columns]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Total records in the data frame: 6079\n"
    }
   ],
   "source": [
    "print(\"Total records in the data frame: {}\" .format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['qa_id', 'question_title', 'question_body', 'question_user_name', 'question_user_page', 'answer', 'answer_user_name', 'answer_user_page', 'url', 'category', 'host']\n"
    }
   ],
   "source": [
    "x_columns = list()\n",
    "x_columns.append(\"qa_id\")\n",
    "\n",
    "for x in df.columns.values[1:].tolist()[0:10] :\n",
    "    x_columns.append(x)\n",
    "\n",
    "y_columns = df.columns.values[1:].tolist()[10:40]\n",
    "# print(df.columns.values[1:][0:10])\n",
    "print(x_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnColumn(x, start, stop) :\n",
    "    return list(x[start:stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(6079, 11)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = list()\n",
    "for row in df.values :\n",
    "    X.append(returnColumn(row, 0, 11))\n",
    "X = pd.DataFrame(X, columns=x_columns)\n",
    "X.head()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(6079, 30)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = list()\n",
    "for row in df.values:\n",
    "    Y.append(returnColumn(row, 11, 41))\n",
    "Y = pd.DataFrame(Y, columns=y_columns)\n",
    "Y.head()\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(4863, 11) (4863, 30)\n(1216, 11) (1216, 30)\n"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop-words from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_title_no_sw = list()\n",
    "for x in X_train[\"question_title\"] :\n",
    "    q_title_no_sw.append(remove_stopwords(x))\n",
    "\n",
    "q_body_no_sw = list()\n",
    "for x in X_train[\"question_body\"] :\n",
    "    q_body_no_sw.append(remove_stopwords(x))\n",
    "\n",
    "answer_no_sw = list()\n",
    "for x in X_train[\"answer\"] :\n",
    "    answer_no_sw.append(remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create object for word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tokenized lists of question_title, question_body and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_q_title = list()\n",
    "for line in q_title_no_sw:\n",
    "    tokenized_q_title.append(tokenizer.tokenize(line.lower()))\n",
    "\n",
    "tokenized_q_body = list()\n",
    "for line in q_body_no_sw:\n",
    "    tokenized_q_body.append(tokenizer.tokenize(line.lower()))\n",
    "\n",
    "tokenized_answer = list()\n",
    "for line in answer_no_sw:\n",
    "    tokenized_answer.append(tokenizer.tokenize(line.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['for', 'novels', 'fiction', 'i', 'prefer', 'e', 'reader', '.', 'for', 'reference', 'i', 'prefer', 'paper', '.', 'why', '?', 'the', 'design', 'teams', 'e', 'readers', 'focus', 'novels', 'assumption', 'going', 'research', 'use', 'computer', '.', 'this', 'problem', 'can', \"'\", 't', 'fixed', ',', 'hasn', \"'\", 't', 'been', '.']\n"
    }
   ],
   "source": [
    "# Checking if the answer block is well tokenized\n",
    "print(tokenized_answer[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "for novels fiction i prefer e reader . for reference i prefer paper . why ? the design teams e readers focus novels assumption going research use computer . this problem can ' t fixed , hasn ' t been .\n"
    }
   ],
   "source": [
    "# Joining the tokenized answer\n",
    "print(' '.join(tokenized_answer[34]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Word2Vec model for vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.parsing.preprocessing import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "I am trying to understand what kinds of places the spam values on p 231 refer to in the 5th Edition main book for Shadowrun.\n\nPer p 15, a sprawl is a plex, a plex is a \"metropolitan complex, short for metroplex\". Per Google a metroplex is \" a very large metropolitan area, especially one that is an aggregation of two or more cities\".  A city downtown and sprawl downtown would tend to have similar densities, but for some reason the sprawl (which includes suburbs?) has a higher spam zone noise rating (p 231).  Similarly, I'd think of a downtown as being more dense and noisy (e.g. Office buildings and street vendors) than a commercial district, e.g. an outdoor mall.  The noise ratings make me think that I am thinking about this incorrectly. What is a better way of thinking of them?\n\nI have command to list system process by memory usage:\n\nps -A --sort -rss -o comm,pmem\n\n\nWhich list a table like\n\nCOMMAND         %MEM\nfirefox         28.2\nchrome           5.4\ncompiz           4.8\natom             2.5\nchrome           2.3\nXorg             2.3\nskype            2.2\nchrome           2.0\nchrome           1.9\natom             1.9\nnautilus         1.8\nhud-service      1.5\nevince           1.3\n\n\nI would like to get total memory share per programs instead of per process of same programs. So I could get output like\n\nCOMMAND         %MEM\nfirefox         28.2\nchrome          11.6\ncompiz           4.8\natom             4.4\nXorg             2.3\nskype            2.2\nnautilus         1.8\nhud-service      1.5\nevince           1.3\n\n\nI thought about using awk, which I don't know much. Ended up with something like:\n\nps -A --sort -rss -o comm,pmem | awk -F \"\\t\" '\n{processes[$0] += $1;}\n{End\nfor(i in processes) {\n  print i,\"\\t\",processes[i];\n}\n}'\n\n\nBut it didn't work.\n\nHow can I correct this?\n\n"
    },
    {
     "data": {
      "text/plain": "'I command list process memory usage: ps -A --sort -rss -o comm,pmem Which list table like COMMAND %MEM firefox 28.2 chrome 5.4 compiz 4.8 atom 2.5 chrome 2.3 Xorg 2.3 skype 2.2 chrome 2.0 chrome 1.9 atom 1.9 nautilus 1.8 hud-service 1.5 evince 1.3 I like total memory share programs instead process programs. So I output like COMMAND %MEM firefox 28.2 chrome 11.6 compiz 4.8 atom 4.4 Xorg 2.3 skype 2.2 nautilus 1.8 hud-service 1.5 evince 1.3 I thought awk, I don\\'t know much. Ended like: ps -A --sort -rss -o comm,pmem | awk -F \"\\\\t\" \\' {processes[$0] += $1;} {End for(i processes) { print i,\"\\\\t\",processes[i]; } }\\' But didn\\'t work. How I correct this?'"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "q_body_no_sw = list()\n",
    "for x in question_body :\n",
    "    q_body_no_sw.append(remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_body_vec_model = Word2Vec(tokenized_q_body, size=40, min_count=5, window=6).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 3.1617975 , -0.23722498,  1.409274  , -1.2606311 ,  1.2696685 ,\n        0.4476379 ,  1.275167  ,  1.7570505 , -1.0324943 ,  1.3642502 ,\n       -1.3477625 ,  0.48774233, -1.049456  , -1.0753771 ,  1.0931644 ,\n       -2.870512  , -0.4607861 , -2.0377328 ,  0.86905247,  0.97090083,\n        2.2748911 , -1.0888474 , -1.7159182 ,  1.833918  ,  0.37761867,\n        0.14117195, -0.28042018,  0.6066532 ,  1.2705051 , -0.5000519 ,\n        3.198017  , -1.1838781 ,  2.0664518 , -0.34193024,  0.7450827 ,\n       -1.0491439 ,  0.7574018 , -1.1073203 ,  1.7441026 , -1.9327567 ],\n      dtype=float32)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_body_vec_model.get_vector(\"the\")       # Some random word in the question_title column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('api', 0.9232462048530579),\n ('mysql', 0.9133329391479492),\n ('directory', 0.9076052904129028),\n ('via', 0.870556652545929),\n ('home', 0.866324782371521),\n ('host', 0.8631211519241333),\n ('vhosts', 0.861056923866272),\n ('facebook', 0.8583757877349854),\n ('cache', 0.8558299541473389),\n ('mysolution', 0.851349413394928)]"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = list()      # All corpus available in the dataset\n",
    "\n",
    "for line in tokenized_q_title:\n",
    "    all_sentences.append(line)\n",
    "\n",
    "for line in tokenized_q_body:\n",
    "    all_sentences.append(line)\n",
    "\n",
    "for line in tokenized_answer:\n",
    "    all_sentences.append(line)\n",
    "\n",
    "# print(all_sentences[100])\n",
    "\n",
    "large_model = Word2Vec(all_sentences, size=40, min_count=5, window=6).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.12671103,  0.56058407,  0.29067558, -0.34022012, -0.2182405 ,\n        0.2881518 , -0.34776968,  0.34765828,  0.36139885,  0.6663553 ,\n       -0.01369049,  0.5019986 ,  0.24421854, -0.02098736, -0.01419102,\n       -0.34052455,  0.33240741, -0.41203988, -0.21594433,  0.23528314,\n        0.5927213 ,  0.4069568 ,  0.06646444, -0.15180974, -0.08081192,\n       -0.01744933, -0.51154923, -0.39859498, -0.05054428,  0.1355095 ,\n        0.3408807 ,  0.09500741,  0.21086383, -0.13736713,  0.49145755,\n        0.53496087,  0.15213656, -0.15006955, -0.04783138,  0.39332587],\n      dtype=float32)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_model.get_vector(\"framework\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('web', 0.8885996341705322),\n ('remote', 0.8876430988311768),\n ('media', 0.8769919872283936),\n ('router', 0.8736147880554199),\n ('desktop', 0.8681355714797974),\n ('library', 0.8669867515563965),\n ('home', 0.8624612092971802),\n ('host', 0.8615283966064453),\n ('directory', 0.8584851622581482),\n ('facebook', 0.8516136407852173)]"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_model.most_similar(\"local\")\n",
    "# large_model.most_similar(positive=[\"project\"], negative=[\"wordpress\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['.', 'up', 'very', 'did', 'option', 'save', 'property', 'problems', 'packages', 'vector']\n"
    }
   ],
   "source": [
    "# Select the 1000 most frequently used words and sort them in descending order based on their frequency of usage\n",
    "words = sorted(model.vocab.keys(), key=lambda word: model.vocab[word].count, reverse=True)[:1000]\n",
    "\n",
    "print(words[::100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python37164bitbasecondaac0852bd93594678aebe973eda693d6e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}